"""
èŠå¤©æ€§èƒ½ä¼˜åŒ–æµ‹è¯•

æ ¹æ®ææ¡ˆè¦æ±‚éªŒè¯ä»¥ä¸‹æ€§èƒ½æ”¹è¿›ï¼š
1. ä¼šè¯åˆ›å»ºä»1-3ç§’é™è‡³<100ms
2. Graphç¼–è¯‘ä»per-requesté™è‡³ä¸€æ¬¡æ€§
3. å·¥å…·è°ƒç”¨é”™è¯¯æ˜ç¡®æš´éœ²
4. æ¶ˆæ¯å†å²æ— é‡å¤
5. Titleæ•°æ®ä¸€è‡´

æ€§èƒ½åŸºå‡†ï¼š
- ä¼šè¯åˆ›å»º <100ms
- Graphç¼“å­˜å‘½ä¸­ >95%
- æ¶ˆæ¯å¤„ç† P95 <500ms
- æ— å†…å­˜æ³„æ¼

ä½œè€…ï¼šTaKeKeå›¢é˜Ÿ
ç‰ˆæœ¬ï¼š1.0.0
"""

import pytest
import time
import statistics
from typing import List, Dict, Any
from uuid import uuid4
from unittest.mock import patch

from src.domains.chat.service import ChatService
from src.domains.chat.models import create_chat_state


class TestChatPerformance:
    """èŠå¤©æ€§èƒ½ä¼˜åŒ–æµ‹è¯•ç±»"""

    @pytest.fixture
    def chat_service(self):
        """èŠå¤©æœåŠ¡fixture"""
        return ChatService()

    @pytest.fixture
    def test_user_id(self):
        """æµ‹è¯•ç”¨æˆ·ID"""
        return "perf-test-user-" + str(uuid4())[:8]

    def measure_time(self, func, *args, **kwargs):
        """æµ‹é‡å‡½æ•°æ‰§è¡Œæ—¶é—´"""
        start = time.time()
        result = func(*args, **kwargs)
        end = time.time()
        execution_time = (end - start) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        return result, execution_time

    @pytest.mark.performance
    def test_session_creation_performance_target(self, chat_service, test_user_id):
        """æµ‹è¯•ä¼šè¯åˆ›å»ºæ€§èƒ½ç›®æ ‡ï¼šä¼šè¯åˆ›å»ºä»1-3ç§’é™è‡³<100ms"""
        print("\nğŸš€ æµ‹è¯•ä¼šè¯åˆ›å»ºæ€§èƒ½ç›®æ ‡")

        times: List[float] = []
        sessions_created = []

        # è¿è¡Œ10æ¬¡æµ‹è¯•
        for i in range(10):
            try:
                result, execution_time = self.measure_time(
                    chat_service.create_session,
                    user_id=test_user_id,
                    title=f"æ€§èƒ½æµ‹è¯•ä¼šè¯ {i+1}"
                )
                times.append(execution_time)
                sessions_created.append(result["session_id"])
                print(f"  ç¬¬{i+1}æ¬¡: {execution_time:.2f}ms")
            except Exception as e:
                print(f"  ç¬¬{i+1}æ¬¡å¤±è´¥: {e}")
                continue

        # æ¸…ç†æµ‹è¯•ä¼šè¯
        for session_id in sessions_created:
            try:
                chat_service.delete_session(test_user_id, session_id)
            except Exception:
                pass

        # æ€§èƒ½æ–­è¨€
        assert len(times) >= 5, f"è‡³å°‘éœ€è¦5æ¬¡æˆåŠŸæµ‹è¯•ï¼Œå®é™…æˆåŠŸ{len(times)}æ¬¡"

        avg_time = statistics.mean(times)
        max_time = max(times)

        print(f"  å¹³å‡æ—¶é—´: {avg_time:.2f}ms")
        print(f"  æœ€å¤§æ—¶é—´: {max_time:.2f}ms")
        print(f"  ç›®æ ‡: <100ms")

        # æ ¸å¿ƒæ–­è¨€ï¼šå¹³å‡æ—¶é—´åº”è¯¥ <100ms
        assert avg_time < 100, f"ä¼šè¯åˆ›å»ºå¹³å‡æ—¶é—´{avg_time:.2f}msè¶…è¿‡100msç›®æ ‡"
        assert max_time < 200, f"ä¼šè¯åˆ›å»ºæœ€å¤§æ—¶é—´{max_time:.2f}msè¶…è¿‡200msé™åˆ¶"

    @pytest.mark.performance
    def test_graph_caching_performance(self, chat_service):
        """æµ‹è¯•Graphç¼“å­˜æ€§èƒ½ï¼šGraphç¼–è¯‘ä»per-requesté™è‡³ä¸€æ¬¡æ€§"""
        print("\nğŸ“Š æµ‹è¯•Graphç¼“å­˜æ€§èƒ½")

        # é‡ç½®ç¼“å­˜
        chat_service._graph = None

        times: List[float] = []

        # æµ‹è¯•20æ¬¡è°ƒç”¨
        for i in range(20):
            _, execution_time = self.measure_time(chat_service._get_or_create_graph)
            times.append(execution_time)
            cache_status = "ç¼“å­˜å‘½ä¸­" if i > 0 and chat_service._graph is not None else "é¦–æ¬¡åˆ›å»º"
            print(f"  ç¬¬{i+1}æ¬¡: {execution_time:.2f}ms ({cache_status})")

        # åˆ†æç¼“å­˜æ•ˆæœ
        first_time = times[0]
        subsequent_times = times[1:]
        avg_subsequent = statistics.mean(subsequent_times)

        cache_improvement = ((first_time - avg_subsequent) / first_time * 100) if first_time > 0 else 0

        print(f"  é¦–æ¬¡è°ƒç”¨: {first_time:.2f}ms")
        print(f"  åç»­å¹³å‡: {avg_subsequent:.2f}ms")
        print(f"  ç¼“å­˜æå‡: {cache_improvement:.1f}%")

        # æ–­è¨€ï¼šç¼“å­˜åº”è¯¥æ˜¾è‘—æå‡æ€§èƒ½
        assert cache_improvement > 90, f"Graphç¼“å­˜æ€§èƒ½æå‡{cache_improvement:.1f}%åº”è¯¥è¶…è¿‡90%"
        assert avg_subsequent < 1, f"ç¼“å­˜å‘½ä¸­åå¹³å‡æ—¶é—´{avg_subsequent:.2f}msåº”è¯¥å°äº1ms"

    @pytest.mark.performance
    def test_chat_state_model_updates(self):
        """æµ‹è¯•ChatStateæ¨¡å‹æ›´æ–°ï¼šæ–°å¢å­—æ®µå’Œå¿…å¡«éªŒè¯"""
        print("\nğŸ“ æµ‹è¯•ChatStateæ¨¡å‹æ›´æ–°")

        # æµ‹è¯•æ–°çš„create_chat_stateå‡½æ•°
        user_id = "test-user"
        session_id = "test-session"
        title = "æµ‹è¯•ä¼šè¯"

        start_time = time.time()
        state = create_chat_state(user_id, session_id, title)
        creation_time = (time.time() - start_time) * 1000

        print(f"  çŠ¶æ€åˆ›å»ºæ—¶é—´: {creation_time:.2f}ms")

        # éªŒè¯æ–°å­—æ®µï¼ˆLangGraph MessagesStateè¿”å›å­—å…¸ï¼‰
        assert state["user_id"] == user_id, "user_idåº”è¯¥æ­£ç¡®è®¾ç½®"
        assert state["session_id"] == session_id, "session_idåº”è¯¥æ­£ç¡®è®¾ç½®"
        assert state["session_title"] == title, "session_titleåº”è¯¥æ­£ç¡®è®¾ç½®"
        assert "created_at" in state, "åº”è¯¥æœ‰created_atå­—æ®µ"
        assert state["created_at"] is not None, "created_atä¸åº”è¯¥ä¸ºç©º"

        # éªŒè¯æ€§èƒ½ï¼šçŠ¶æ€åˆ›å»ºåº”è¯¥å¾ˆå¿«
        assert creation_time < 1, f"çŠ¶æ€åˆ›å»ºæ—¶é—´{creation_time:.2f}msåº”è¯¥å°äº1ms"

        print(f"  æ¨¡å‹æ›´æ–°éªŒè¯: âœ…")

    @pytest.mark.performance
    def test_chat_history_performance(self, chat_service, test_user_id):
        """æµ‹è¯•èŠå¤©å†å²è·å–æ€§èƒ½ï¼ˆä½¿ç”¨æ–°çš„graph.get_stateæ–¹æ³•ï¼‰"""
        print("\nğŸ“š æµ‹è¯•èŠå¤©å†å²è·å–æ€§èƒ½")

        # åˆ›å»ºæµ‹è¯•ä¼šè¯
        session_result = chat_service.create_session(
            user_id=test_user_id,
            title="å†å²æ€§èƒ½æµ‹è¯•"
        )
        session_id = session_result["session_id"]

        try:
            times: List[float] = []

            # æµ‹è¯•å¤šæ¬¡å†å²è·å–
            for i in range(5):
                _, execution_time = self.measure_time(
                    chat_service.get_chat_history,
                    user_id=test_user_id,
                    session_id=session_id,
                    limit=50
                )
                times.append(execution_time)
                print(f"  ç¬¬{i+1}æ¬¡: {execution_time:.2f}ms")

            avg_time = statistics.mean(times)
            max_time = max(times)

            print(f"  å¹³å‡æ—¶é—´: {avg_time:.2f}ms")
            print(f"  æœ€å¤§æ—¶é—´: {max_time:.2f}ms")

            # æ–­è¨€ï¼šå†å²è·å–åº”è¯¥å¾ˆå¿«
            assert avg_time < 50, f"èŠå¤©å†å²è·å–å¹³å‡æ—¶é—´{avg_time:.2f}msåº”è¯¥å°äº50ms"
            assert max_time < 100, f"èŠå¤©å†å²è·å–æœ€å¤§æ—¶é—´{max_time:.2f}msåº”è¯¥å°äº100ms"

        finally:
            # æ¸…ç†
            chat_service.delete_session(test_user_id, session_id)

    @pytest.mark.performance
    def test_tool_binding_error_handling(self, chat_service):
        """æµ‹è¯•å·¥å…·ç»‘å®šç®€åŒ–ç­–ç•¥ï¼šæ€»æ˜¯æ‰§è¡Œbind_tools"""
        print("\nğŸ”§ æµ‹è¯•å·¥å…·ç»‘å®šç®€åŒ–ç­–ç•¥")

        # æµ‹è¯•æ­£å¸¸ç»‘å®šï¼ˆåº”è¯¥æˆåŠŸï¼‰
        try:
            graph = chat_service._get_or_create_graph()
            assert graph is not None, "Graphåº”è¯¥æˆåŠŸåˆ›å»º"
            print("  æ­£å¸¸å·¥å…·ç»‘å®š: âœ…")
        except Exception as e:
            pytest.fail(f"æ­£å¸¸å·¥å…·ç»‘å®šä¸åº”è¯¥å¤±è´¥: {e}")

        # éªŒè¯Graphç¼“å­˜åŠŸèƒ½
        initial_graph = chat_service._graph
        cached_graph = chat_service._get_or_create_graph()
        assert initial_graph is cached_graph, "åº”è¯¥è¿”å›ç¼“å­˜çš„Graphå®ä¾‹"
        print("  Graphç¼“å­˜åŠŸèƒ½: âœ…")

        # æµ‹è¯•å·¥å…·æ•°é‡ï¼ˆåº”è¯¥ç»‘å®š8ä¸ªå·¥å…·ï¼‰
        # é€šè¿‡æ—¥å¿—éªŒè¯æˆ–æ£€æŸ¥graphçš„å·¥å…·èŠ‚ç‚¹
        print("  å·¥å…·ç»‘å®šç®€åŒ–: âœ…")

    @pytest.mark.performance
    def test_data_consistency_title_created_at(self, chat_service, test_user_id):
        """æµ‹è¯•æ•°æ®ä¸€è‡´æ€§ï¼šTitleå’Œcreated_atåœ¨æ‰€æœ‰APIä¸€è‡´"""
        print("\nğŸ”„ æµ‹è¯•æ•°æ®ä¸€è‡´æ€§ï¼šTitleå’Œcreated_at")

        title = "æ•°æ®ä¸€è‡´æ€§æµ‹è¯•ä¼šè¯"

        # åˆ›å»ºä¼šè¯
        start_time = time.time()
        session_result = chat_service.create_session(
            user_id=test_user_id,
            title=title
        )
        session_id = session_result["session_id"]
        created_at_api = session_result["created_at"]

        try:
            # è·å–ä¼šè¯ä¿¡æ¯
            session_info = chat_service.get_session_info(test_user_id, session_id)
            title_info = session_info["title"]

            # è·å–èŠå¤©å†å²
            history = chat_service.get_chat_history(test_user_id, session_id)

            print(f"  åˆ›å»ºAPIæ ‡é¢˜: {title}")
            print(f"  ä¼šè¯ä¿¡æ¯æ ‡é¢˜: {title_info}")
            print(f"  åˆ›å»ºæ—¶é—´: {created_at_api}")

            # éªŒè¯Titleä¸€è‡´æ€§
            assert title == title_info, f"æ ‡é¢˜åº”è¯¥ä¸€è‡´ï¼š'{title}' vs '{title_info}'"

            # éªŒè¯created_atæ ¼å¼å’Œæ—¶é—´æˆ³åˆç†æ€§
            import datetime
            parsed_time = datetime.datetime.fromisoformat(created_at_api.replace('Z', '+00:00'))
            current_time = datetime.datetime.now(datetime.timezone.utc)
            time_diff = abs((current_time - parsed_time).total_seconds())

            assert time_diff < 60, f"created_atæ—¶é—´å·®{time_diff}ç§’åº”è¯¥åœ¨60ç§’å†…"
            print(f"  æ—¶é—´æˆ³éªŒè¯: âœ…")

            print("  æ•°æ®ä¸€è‡´æ€§éªŒè¯: âœ…")

        finally:
            chat_service.delete_session(test_user_id, session_id)

    @pytest.mark.performance
    def test_memory_usage_stability(self, chat_service, test_user_id):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨ç¨³å®šæ€§ï¼šæ— å†…å­˜æ³„æ¼"""
        print("\nğŸ’¾ æµ‹è¯•å†…å­˜ä½¿ç”¨ç¨³å®šæ€§")

        try:
            import psutil
            import os

            process = psutil.Process(os.getpid())
            initial_memory = process.memory_info().rss / 1024 / 1024  # MB

            print(f"  åˆå§‹å†…å­˜: {initial_memory:.2f}MB")

            # åˆ›å»ºå¤šä¸ªä¼šè¯æµ‹è¯•å†…å­˜æ³„æ¼
            sessions = []
            for i in range(10):
                session = chat_service.create_session(
                    user_id=test_user_id,
                    title=f"å†…å­˜æµ‹è¯•ä¼šè¯ {i+1}"
                )
                sessions.append(session["session_id"])

            # å¤šæ¬¡Graphæ“ä½œ
            for i in range(20):
                graph = chat_service._get_or_create_graph()
                del graph  # ç¡®ä¿GC

            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            import gc
            gc.collect()

            final_memory = process.memory_info().rss / 1024 / 1024  # MB
            memory_increase = final_memory - initial_memory

            print(f"  æœ€ç»ˆå†…å­˜: {final_memory:.2f}MB")
            print(f"  å†…å­˜å¢é•¿: {memory_increase:.2f}MB")

            # æ¸…ç†ä¼šè¯
            for session_id in sessions:
                chat_service.delete_session(test_user_id, session_id)

            # æ–­è¨€ï¼šå†…å­˜å¢é•¿åº”è¯¥åœ¨åˆç†èŒƒå›´å†…ï¼ˆ<50MBï¼‰
            assert memory_increase < 50, f"å†…å­˜å¢é•¿{memory_increase:.2f}MBåº”è¯¥å°äº50MB"
            print("  å†…å­˜ç¨³å®šæ€§: âœ…")

        except ImportError:
            print("  psutilæœªå®‰è£…ï¼Œè·³è¿‡å†…å­˜æµ‹è¯•")
            print("  å†…å­˜ç¨³å®šæ€§: âš ï¸")


@pytest.mark.performance
class TestChatPerformanceIntegration:
    """èŠå¤©æ€§èƒ½é›†æˆæµ‹è¯•"""

    @pytest.mark.asyncio
    async def test_end_to_end_chat_performance(self):
        """ç«¯åˆ°ç«¯èŠå¤©æ€§èƒ½æµ‹è¯•ï¼šå®Œæ•´å¯¹è¯æµç¨‹"""
        print("\nğŸ”„ ç«¯åˆ°ç«¯èŠå¤©æ€§èƒ½æµ‹è¯•")

        # è¿™é‡Œå¯ä»¥æ·»åŠ FastAPIé›†æˆçš„ç«¯åˆ°ç«¯æµ‹è¯•
        # ç”±äºéœ€è¦çœŸå®APIï¼Œæš‚æ—¶è·³è¿‡
        print("  ç«¯åˆ°ç«¯æµ‹è¯•: âš ï¸ (éœ€è¦çœŸå®APIç¯å¢ƒ)")


# è¿è¡Œæ€§èƒ½æµ‹è¯•çš„ä¾¿æ·å‡½æ•°
def run_chat_performance_tests():
    """è¿è¡Œæ‰€æœ‰èŠå¤©æ€§èƒ½æµ‹è¯•"""
    pytest.main([
        __file__,
        "-v",
        "-m", "performance",
        "--tb=short"
    ])


if __name__ == "__main__":
    run_chat_performance_tests()