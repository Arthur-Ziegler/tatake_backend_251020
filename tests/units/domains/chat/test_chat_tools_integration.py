"""
èŠå¤©å·¥å…·é›†æˆæµ‹è¯•å¥—ä»¶

æµ‹è¯•é©±åŠ¨å¼€å‘ï¼ˆTDDï¼‰ï¼šå…ˆç¼–å†™æµ‹è¯•ï¼Œå†å®ç°åŠŸèƒ½ã€‚
æœ¬æ–‡ä»¶åŒ…å«å¯¹æ‰€æœ‰8ä¸ªèŠå¤©å·¥å…·çš„é›†æˆæµ‹è¯•ï¼ŒéªŒè¯å·¥å…·ååŒå·¥ä½œèƒ½åŠ›ã€‚

æµ‹è¯•è¦†ç›–èŒƒå›´ï¼š
1. å®Œæ•´å·¥ä½œæµç¨‹ï¼šåˆ›å»ºä»»åŠ¡->æŸ¥è¯¢ä»»åŠ¡->æœç´¢ä»»åŠ¡->æ‰¹é‡æ“ä½œ->åˆ é™¤ä»»åŠ¡
2. å·¥å…·é“¾å¼è°ƒç”¨ï¼šå¤šä¸ªå·¥å…·æŒ‰åºè°ƒç”¨çš„åœºæ™¯
3. å¤æ‚ä¸šåŠ¡åœºæ™¯ï¼šæ¨¡æ‹ŸçœŸå®ç”¨æˆ·ä½¿ç”¨åœºæ™¯
4. é”™è¯¯æ¢å¤ï¼šå·¥å…·è°ƒç”¨å¤±è´¥æ—¶çš„æ¢å¤æœºåˆ¶
5. æ€§èƒ½é›†æˆï¼šå¤šä¸ªå·¥å…·è°ƒç”¨çš„æ•´ä½“æ€§èƒ½
6. LangGraphé›†æˆï¼šåœ¨LangGraphç¯å¢ƒä¸­çš„å·¥å…·è°ƒç”¨

8ä¸ªå·¥å…·åˆ—è¡¨ï¼š
1. sesame_opener - èŠéº»å¼€é—¨å·¥å…·
2. calculator - è®¡ç®—å™¨å·¥å…·
3. query_tasks - ä»»åŠ¡æŸ¥è¯¢å·¥å…·
4. get_task_detail - ä»»åŠ¡è¯¦æƒ…å·¥å…·
5. create_task - åˆ›å»ºä»»åŠ¡å·¥å…·
6. update_task - æ›´æ–°ä»»åŠ¡å·¥å…·
7. delete_task - åˆ é™¤ä»»åŠ¡å·¥å…·
8. search_tasks - æœç´¢ä»»åŠ¡å·¥å…·
9. batch_create_subtasks - æ‰¹é‡åˆ›å»ºå­ä»»åŠ¡å·¥å…·

è®¾è®¡åŸåˆ™ï¼š
1. ç«¯åˆ°ç«¯æµ‹è¯•ï¼šæ¨¡æ‹Ÿå®Œæ•´ç”¨æˆ·å·¥ä½œæµç¨‹
2. çœŸå®åœºæ™¯ï¼šåŸºäºå®é™…ä½¿ç”¨åœºæ™¯è®¾è®¡æµ‹è¯•ç”¨ä¾‹
3. å·¥å…·åä½œï¼šéªŒè¯å·¥å…·é—´çš„æ•°æ®ä¼ é€’å’ŒçŠ¶æ€ç®¡ç†
4. é”™è¯¯å¤„ç†ï¼šæµ‹è¯•æ•´ä¸ªå·¥å…·é“¾çš„é”™è¯¯å¤„ç†èƒ½åŠ›
5. æ€§èƒ½éªŒè¯ï¼šç¡®ä¿é›†æˆåçš„æ€§èƒ½æ»¡è¶³è¦æ±‚

ä½œè€…ï¼šTaKeKeå›¢é˜Ÿ
ç‰ˆæœ¬ï¼š1.0.0
"""

import pytest
import logging
import json
import time
from unittest.mock import Mock, patch, MagicMock
from uuid import UUID, uuid4
from datetime import datetime, timezone
from typing import Dict, Any, List

# å¯¼å…¥æµ‹è¯•åŸºç¡€è®¾æ–½
from .test_chat_tools_infrastructure import (
    ToolCallLogger,
    MockToolServiceContext,
    ToolResponseValidator,
    ToolTestDataFactory,
    ChatToolsTestConfig
)

# å¯¼å…¥æ‰€æœ‰å·¥å…·
from src.domains.chat.tools.sesame_opener import sesame_opener
from src.domains.chat.tools.calculator import calculator
from src.domains.chat.tools.task_query import query_tasks, get_task_detail
from src.domains.chat.tools.task_crud import create_task, update_task, delete_task
from src.domains.chat.tools.task_search import search_tasks
from src.domains.chat.tools.task_batch import batch_create_subtasks

# æµ‹è¯•ç”¨ä¾‹ä¸“ç”¨çš„logger
logger = logging.getLogger(__name__)


class TestCompleteWorkflow:
    """æµ‹è¯•å®Œæ•´çš„ä»»åŠ¡ç®¡ç†å·¥ä½œæµç¨‹"""

    @patch('src.domains.chat.tools.utils.get_task_service_context')
    def test_complete_task_lifecycle(self, mock_context):
        """æµ‹è¯•å®Œæ•´çš„ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸï¼šåˆ›å»º->æŸ¥è¯¢->æ›´æ–°->æœç´¢->åˆ é™¤"""

        user_id = ChatToolsTestConfig.TEST_USER_ID
        task_service = Mock()
        mock_context.return_value.__enter__.return_value = {
            'task_service': task_service,
            'points_service': Mock()
        }

        # 1. åˆ›å»ºä»»åŠ¡
        logger.info("ğŸ”„ æ­¥éª¤1ï¼šåˆ›å»ºä»»åŠ¡")
        task_data = {
            'title': 'é›†æˆæµ‹è¯•ä»»åŠ¡',
            'description': 'è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„é›†æˆæµ‹è¯•ä»»åŠ¡',
            'priority': 'high',
            'status': 'pending',
            'user_id': user_id
        }

        created_task = {
            'id': str(uuid4()),
            'title': task_data['title'],
            'description': task_data['description'],
            'status': task_data['status'],
            'priority': task_data['priority'],
            'user_id': user_id,
            'created_at': datetime.now(timezone.utc).isoformat(),
            'updated_at': datetime.now(timezone.utc).isoformat()
        }

        task_service.create_task.return_value = created_task

        create_result = create_task.invoke(task_data)
        create_data = json.loads(create_result)

        assert ToolResponseValidator.validate_success_response(create_result), "åˆ›å»ºä»»åŠ¡å¤±è´¥"
        task_id = create_data['data']['task']['id']
        logger.info(f"âœ… ä»»åŠ¡åˆ›å»ºæˆåŠŸï¼ŒID: {task_id}")

        # 2. æŸ¥è¯¢ä»»åŠ¡åˆ—è¡¨
        logger.info("ğŸ”„ æ­¥éª¤2ï¼šæŸ¥è¯¢ä»»åŠ¡åˆ—è¡¨")
        task_service.get_tasks.return_value = [created_task]

        query_result = query_tasks.invoke({'user_id': user_id})
        query_data = json.loads(query_result)

        assert ToolResponseValidator.validate_success_response(query_result), "æŸ¥è¯¢ä»»åŠ¡å¤±è´¥"
        assert len(query_data['data']['tasks']) == 1
        assert query_data['data']['tasks'][0]['id'] == task_id
        logger.info(f"âœ… ä»»åŠ¡æŸ¥è¯¢æˆåŠŸï¼Œæ‰¾åˆ°1ä¸ªä»»åŠ¡")

        # 3. è·å–ä»»åŠ¡è¯¦æƒ…
        logger.info("ğŸ”„ æ­¥éª¤3ï¼šè·å–ä»»åŠ¡è¯¦æƒ…")
        task_service.get_task.return_value = created_task

        detail_result = get_task_detail.invoke({'task_id': task_id, 'user_id': user_id})
        detail_data = json.loads(detail_result)

        assert ToolResponseValidator.validate_success_response(detail_result), "è·å–ä»»åŠ¡è¯¦æƒ…å¤±è´¥"
        assert detail_data['data']['task']['id'] == task_id
        logger.info(f"âœ… ä»»åŠ¡è¯¦æƒ…è·å–æˆåŠŸ")

        # 4. æ›´æ–°ä»»åŠ¡
        logger.info("ğŸ”„ æ­¥éª¤4ï¼šæ›´æ–°ä»»åŠ¡")
        updated_task = created_task.copy()
        updated_task['status'] = 'in_progress'
        updated_task['description'] = 'å·²æ›´æ–°çš„ä»»åŠ¡æè¿°'

        task_service.update_task_with_tree_structure.return_value = updated_task

        update_result = update_task.invoke({
            'task_id': task_id,
            'status': 'in_progress',
            'description': 'å·²æ›´æ–°çš„ä»»åŠ¡æè¿°',
            'user_id': user_id
        })
        update_data = json.loads(update_result)

        assert ToolResponseValidator.validate_success_response(update_result), "æ›´æ–°ä»»åŠ¡å¤±è´¥"
        assert update_data['data']['task']['status'] == 'in_progress'
        logger.info(f"âœ… ä»»åŠ¡æ›´æ–°æˆåŠŸ")

        # 5. æœç´¢ä»»åŠ¡
        logger.info("ğŸ”„ æ­¥éª¤5ï¼šæœç´¢ä»»åŠ¡")
        task_service.get_tasks.return_value = [updated_task]

        search_result = search_tasks.invoke({
            'query': 'é›†æˆæµ‹è¯•',
            'limit': 10,
            'state': None,
            'user_id': user_id  # æ³¨æ„ï¼šsearch_tasksçš„å®ç°ä¸­user_idå¤„ç†å¯èƒ½ä¸åŒ
        })
        search_data = json.loads(search_result)

        assert search_data['success'] is True, "æœç´¢ä»»åŠ¡å¤±è´¥"
        assert len(search_data['tasks']) >= 1
        logger.info(f"âœ… ä»»åŠ¡æœç´¢æˆåŠŸï¼Œæ‰¾åˆ°{len(search_data['tasks'])}ä¸ªä»»åŠ¡")

        # 6. åˆ é™¤ä»»åŠ¡
        logger.info("ğŸ”„ æ­¥éª¤6ï¼šåˆ é™¤ä»»åŠ¡")
        task_service.delete_task.return_value = {
            'deleted_task_id': task_id,
            'deleted_subtasks_count': 0
        }

        delete_result = delete_task.invoke({'task_id': task_id, 'user_id': user_id})
        delete_data = json.loads(delete_result)

        assert ToolResponseValidator.validate_success_response(delete_result), "åˆ é™¤ä»»åŠ¡å¤±è´¥"
        assert delete_data['data']['deleted_task_id'] == task_id
        logger.info(f"âœ… ä»»åŠ¡åˆ é™¤æˆåŠŸ")

        logger.info("ğŸ‰ å®Œæ•´ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸæµ‹è¯•é€šè¿‡ï¼")

    @patch('src.domains.chat.tools.utils.get_task_service_context')
    def test_task_decomposition_workflow(self, mock_context):
        """æµ‹è¯•ä»»åŠ¡åˆ†è§£å·¥ä½œæµç¨‹ï¼šåˆ›å»ºçˆ¶ä»»åŠ¡->æ‰¹é‡åˆ›å»ºå­ä»»åŠ¡->ç®¡ç†å­ä»»åŠ¡"""

        user_id = ChatToolsTestConfig.TEST_USER_ID
        task_service = Mock()
        mock_context.return_value.__enter__.return_value = {
            'task_service': task_service,
            'points_service': Mock()
        }

        # 1. åˆ›å»ºçˆ¶ä»»åŠ¡
        logger.info("ğŸ”„ æ­¥éª¤1ï¼šåˆ›å»ºçˆ¶ä»»åŠ¡")
        parent_task = {
            'id': str(uuid4()),
            'title': 'é¡¹ç›®å¼€å‘',
            'description': 'å¼€å‘ä¸€ä¸ªå®Œæ•´çš„é¡¹ç›®',
            'status': 'pending',
            'priority': 'high',
            'user_id': user_id,
            'created_at': datetime.now(timezone.utc).isoformat()
        }

        task_service.create_task.return_value = parent_task
        task_service.get_task_by_id.return_value = parent_task

        create_result = create_task.invoke({
            'title': 'é¡¹ç›®å¼€å‘',
            'description': 'å¼€å‘ä¸€ä¸ªå®Œæ•´çš„é¡¹ç›®',
            'priority': 'high',
            'user_id': user_id
        })

        assert ToolResponseValidator.validate_success_response(create_result)
        parent_id = parent_task['id']
        logger.info(f"âœ… çˆ¶ä»»åŠ¡åˆ›å»ºæˆåŠŸï¼ŒID: {parent_id}")

        # 2. æ‰¹é‡åˆ›å»ºå­ä»»åŠ¡
        logger.info("ğŸ”„ æ­¥éª¤2ï¼šæ‰¹é‡åˆ›å»ºå­ä»»åŠ¡")
        subtasks = [
            {"title": "éœ€æ±‚åˆ†æ", "description": "åˆ†æç”¨æˆ·éœ€æ±‚"},
            {"title": "ç³»ç»Ÿè®¾è®¡", "description": "è®¾è®¡ç³»ç»Ÿæ¶æ„"},
            {"title": "ç¼–ç å®ç°", "description": "ç¼–å†™ä»£ç å®ç°åŠŸèƒ½"},
            {"title": "æµ‹è¯•éªŒè¯", "description": "è¿›è¡ŒåŠŸèƒ½æµ‹è¯•"}
        ]

        created_subtasks = []
        for i, subtask in enumerate(subtasks):
            created_subtasks.append({
                'id': str(uuid4()),
                'title': subtask['title'],
                'description': subtask['description'],
                'status': 'pending',
                'parent_id': parent_id,
                'user_id': user_id,
                'created_at': datetime.now(timezone.utc).isoformat()
            })

        task_service.create_task.side_effect = created_subtasks

        batch_result = batch_create_subtasks.invoke({
            'parent_id': parent_id,
            'subtasks': subtasks,
            'user_id': user_id
        })
        batch_data = json.loads(batch_result)

        assert batch_data['success'] is True
        assert batch_data['data']['total'] == 4
        assert batch_data['data']['success_count'] == 4
        assert len(batch_data['data']['created']) == 4
        logger.info(f"âœ… æ‰¹é‡åˆ›å»ºå­ä»»åŠ¡æˆåŠŸï¼Œåˆ›å»º{batch_data['data']['success_count']}ä¸ªå­ä»»åŠ¡")

        # 3. æŸ¥è¯¢å­ä»»åŠ¡
        logger.info("ğŸ”„ æ­¥éª¤3ï¼šæŸ¥è¯¢å­ä»»åŠ¡")
        all_tasks = [parent_task] + created_subtasks
        task_service.get_tasks.return_value = all_tasks

        query_result = query_tasks.invoke({'user_id': user_id})
        query_data = json.loads(query_result)

        assert ToolResponseValidator.validate_success_response(query_result)
        assert len(query_data['data']['tasks']) == 5  # 1ä¸ªçˆ¶ä»»åŠ¡ + 4ä¸ªå­ä»»åŠ¡
        logger.info(f"âœ… æŸ¥è¯¢åˆ°æ‰€æœ‰ä»»åŠ¡ï¼Œå…±{len(query_data['data']['tasks'])}ä¸ª")

        # 4. æœç´¢ç‰¹å®šå­ä»»åŠ¡
        logger.info("ğŸ”„ æ­¥éª¤4ï¼šæœç´¢å­ä»»åŠ¡")
        design_tasks = [task for task in all_tasks if 'è®¾è®¡' in task['title']]
        task_service.get_tasks.return_value = design_tasks

        search_result = search_tasks.invoke({
            'query': 'è®¾è®¡',
            'limit': 10,
            'state': None,
            'user_id': user_id
        })
        search_data = json.loads(search_result)

        assert search_data['success'] is True
        assert len(search_data['tasks']) >= 1
        logger.info(f"âœ… æœç´¢åˆ°è®¾è®¡ç›¸å…³ä»»åŠ¡{len(search_data['tasks'])}ä¸ª")

        logger.info("ğŸ‰ ä»»åŠ¡åˆ†è§£å·¥ä½œæµç¨‹æµ‹è¯•é€šè¿‡ï¼")


class TestToolChaining:
    """æµ‹è¯•å·¥å…·é“¾å¼è°ƒç”¨"""

    def test_sesame_opener_calculator_chain(self):
        """æµ‹è¯•èŠéº»å¼€é—¨+è®¡ç®—å™¨å·¥å…·é“¾"""

        # 1. èŠéº»å¼€é—¨éªŒè¯
        logger.info("ğŸ”„ æ­¥éª¤1ï¼šèŠéº»å¼€é—¨å·¥å…·éªŒè¯")
        sesame_result = sesame_opener.invoke({'command': 'èŠéº»å¼€é—¨'})
        assert ToolResponseValidator.validate_success_response(sesame_result)
        logger.info("âœ… èŠéº»å¼€é—¨å·¥å…·è°ƒç”¨æˆåŠŸ")

        # 2. è®¡ç®—å™¨å·¥å…·é“¾å¼è°ƒç”¨
        logger.info("ğŸ”„ æ­¥éª¤2ï¼šè®¡ç®—å™¨å·¥å…·é“¾")
        calculations = [
            ('10 + 5', '15'),
            ('20 * 3', '60'),
            ('100 / 4', '25.0'),
            ('50 - 15', '35')
        ]

        for expression, expected in calculations:
            calc_result = calculator.invoke({'expression': expression})
            assert ToolResponseValidator.validate_success_response(calc_result)
            calc_data = json.loads(calc_result)
            assert expected in calc_data['data']
            logger.info(f"âœ… è®¡ç®— {expression} = {expected}")

        logger.info("ğŸ‰ èŠéº»å¼€é—¨+è®¡ç®—å™¨å·¥å…·é“¾æµ‹è¯•é€šè¿‡ï¼")

    @patch('src.domains.chat.tools.utils.get_task_service_context')
    def test_task_management_tool_chain(self, mock_context):
        """æµ‹è¯•ä»»åŠ¡ç®¡ç†å·¥å…·é“¾"""

        user_id = ChatToolsTestConfig.TEST_USER_ID
        task_service = Mock()
        mock_context.return_value.__enter__.return_value = {
            'task_service': task_service,
            'points_service': Mock()
        }

        # åˆ›å»ºå¤šä¸ªç›¸å…³ä»»åŠ¡
        tasks = []
        for i in range(3):
            task = {
                'id': str(uuid4()),
                'title': f'ä»»åŠ¡{i+1}',
                'description': f'ç¬¬{i+1}ä¸ªä»»åŠ¡çš„æè¿°',
                'status': 'pending',
                'priority': 'medium',
                'user_id': user_id,
                'created_at': datetime.now(timezone.utc).isoformat()
            }
            tasks.append(task)

        # å·¥å…·é“¾ï¼šåˆ›å»º->æŸ¥è¯¢->æ›´æ–°->æœç´¢
        logger.info("ğŸ”„ ä»»åŠ¡ç®¡ç†å·¥å…·é“¾æµ‹è¯•")

        # 1. æ‰¹é‡åˆ›å»º
        task_service.create_task.side_effect = tasks
        created_ids = []

        for i, task in enumerate(tasks):
            create_result = create_task.invoke({
                'title': task['title'],
                'description': task['description'],
                'user_id': user_id
            })
            assert ToolResponseValidator.validate_success_response(create_result)
            create_data = json.loads(create_result)
            created_ids.append(create_data['data']['task']['id'])
            logger.info(f"âœ… åˆ›å»ºä»»åŠ¡{i+1}: {task['title']}")

        # 2. æŸ¥è¯¢æ‰€æœ‰ä»»åŠ¡
        task_service.get_tasks.return_value = tasks
        query_result = query_tasks.invoke({'user_id': user_id})
        assert ToolResponseValidator.validate_success_response(query_result)
        query_data = json.loads(query_result)
        assert len(query_data['data']['tasks']) == 3
        logger.info("âœ… æŸ¥è¯¢åˆ°3ä¸ªä»»åŠ¡")

        # 3. æ‰¹é‡æ›´æ–°çŠ¶æ€
        for i, task_id in enumerate(created_ids):
            updated_task = tasks[i].copy()
            updated_task['status'] = 'completed'
            task_service.update_task_with_tree_structure.return_value = updated_task

            update_result = update_task.invoke({
                'task_id': task_id,
                'status': 'completed',
                'user_id': user_id
            })
            assert ToolResponseValidator.validate_success_response(update_result)
            logger.info(f"âœ… æ›´æ–°ä»»åŠ¡{i+1}çŠ¶æ€ä¸ºå·²å®Œæˆ")

        # 4. æœç´¢å·²å®Œæˆçš„ä»»åŠ¡
        completed_tasks = [task for task in tasks if task['status'] == 'completed']
        task_service.get_tasks.return_value = completed_tasks

        search_result = search_tasks.invoke({
            'query': 'å·²å®Œæˆ',
            'limit': 10,
            'state': 'completed',
            'user_id': user_id
        })
        search_data = json.loads(search_result)
        assert search_data['success'] is True
        logger.info("âœ… æœç´¢åˆ°å·²å®Œæˆä»»åŠ¡")

        logger.info("ğŸ‰ ä»»åŠ¡ç®¡ç†å·¥å…·é“¾æµ‹è¯•é€šè¿‡ï¼")


class TestErrorHandlingAndRecovery:
    """æµ‹è¯•é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶"""

    @patch('src.domains.chat.tools.utils.get_task_service_context')
    def test_partial_failure_recovery(self, mock_context):
        """æµ‹è¯•éƒ¨åˆ†å¤±è´¥æ—¶çš„æ¢å¤æœºåˆ¶"""

        user_id = ChatToolsTestConfig.TEST_USER_ID
        task_service = Mock()
        mock_context.return_value.__enter__.return_value = {
            'task_service': task_service,
            'points_service': Mock()
        }

        # æ¨¡æ‹Ÿéƒ¨åˆ†åˆ›å»ºå¤±è´¥çš„åœºæ™¯
        logger.info("ğŸ”„ æµ‹è¯•éƒ¨åˆ†å¤±è´¥æ¢å¤æœºåˆ¶")

        subtasks = [
            {"title": "ä»»åŠ¡1", "description": "ç¬¬ä¸€ä¸ªä»»åŠ¡"},
            {"title": "ä»»åŠ¡2", "description": "ç¬¬äºŒä¸ªä»»åŠ¡"},
            {"title": "ä»»åŠ¡3", "description": "ç¬¬ä¸‰ä¸ªä»»åŠ¡"}
        ]

        parent_task = {
            'id': str(uuid4()),
            'title': 'çˆ¶ä»»åŠ¡',
            'user_id': user_id,
            'status': 'pending'
        }

        task_service.get_task_by_id.return_value = parent_task

        # æ¨¡æ‹Ÿç¬¬2ä¸ªä»»åŠ¡åˆ›å»ºå¤±è´¥
        def mock_create_task(request, user_uuid):
            if request.title == "ä»»åŠ¡2":
                raise Exception("æ¨¡æ‹Ÿåˆ›å»ºå¤±è´¥")
            return {
                'id': str(uuid4()),
                'title': request.title,
                'description': request.description,
                'status': 'pending',
                'user_id': str(user_uuid),
                'created_at': datetime.now(timezone.utc).isoformat()
            }

        task_service.create_task.side_effect = mock_create_task

        # æ‰§è¡Œæ‰¹é‡åˆ›å»º
        batch_result = batch_create_subtasks.invoke({
            'parent_id': parent_task['id'],
            'subtasks': subtasks,
            'user_id': user_id
        })
        batch_data = json.loads(batch_result)

        # éªŒè¯éƒ¨åˆ†æˆåŠŸå¤„ç†
        assert batch_data['success'] is True  # å·¥å…·æ•´ä½“æˆåŠŸ
        assert batch_data['data']['total'] == 3
        assert batch_data['data']['success_count'] == 2
        assert batch_data['data']['failure_count'] == 1
        assert len(batch_data['data']['created']) == 2
        assert len(batch_data['data']['failed']) == 1

        logger.info(f"âœ… éƒ¨åˆ†å¤±è´¥æ¢å¤æµ‹è¯•ï¼šæˆåŠŸ{batch_data['data']['success_count']}ä¸ªï¼Œå¤±è´¥{batch_data['data']['failure_count']}ä¸ª")

    @patch('src.domains.chat.tools.utils.get_task_service_context')
    def test_cascading_error_handling(self, mock_context):
        """æµ‹è¯•çº§è”é”™è¯¯å¤„ç†"""

        user_id = ChatToolsTestConfig.TEST_USER_ID
        task_service = Mock()
        mock_context.return_value.__enter__.return_value = {
            'task_service': task_service,
            'points_service': Mock()
        }

        logger.info("ğŸ”„ æµ‹è¯•çº§è”é”™è¯¯å¤„ç†")

        # 1. ä»»åŠ¡ä¸å­˜åœ¨æ—¶çš„é”™è¯¯å¤„ç†
        task_service.get_task.return_value = None

        detail_result = get_task_detail.invoke({
            'task_id': str(uuid4()),
            'user_id': user_id
        })
        detail_data = json.loads(detail_result)

        assert detail_data['success'] is False
        assert 'TASK_NOT_FOUND' in str(detail_data)
        logger.info("âœ… ä»»åŠ¡ä¸å­˜åœ¨é”™è¯¯å¤„ç†æ­£ç¡®")

        # 2. æ— æ•ˆå‚æ•°é”™è¯¯å¤„ç†
        calc_result = calculator.invoke({'expression': 'invalid math'})
        calc_data = json.loads(calc_result)

        assert calc_data['success'] is False
        assert 'CALCULATION_ERROR' in str(calc_data)
        logger.info("âœ… è®¡ç®—å™¨é”™è¯¯å¤„ç†æ­£ç¡®")

        # 3. æƒé™é”™è¯¯å¤„ç†
        task_service.get_task_by_id.return_value = {
            'id': str(uuid4()),
            'title': 'å…¶ä»–ç”¨æˆ·çš„ä»»åŠ¡',
            'user_id': str(uuid4())  # ä¸åŒçš„ç”¨æˆ·ID
        }

        batch_result = batch_create_subtasks.invoke({
            'parent_id': str(uuid4()),
            'subtasks': [{"title": "æµ‹è¯•ä»»åŠ¡"}],
            'user_id': user_id
        })
        batch_data = json.loads(batch_result)

        assert batch_data['success'] is False
        assert 'PERMISSION_DENIED' in str(batch_data)
        logger.info("âœ… æƒé™é”™è¯¯å¤„ç†æ­£ç¡®")

        logger.info("ğŸ‰ çº§è”é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡ï¼")


class TestPerformanceIntegration:
    """é›†æˆæ€§èƒ½æµ‹è¯•"""

    @patch('src.domains.chat.tools.utils.get_task_service_context')
    def test_high_volume_operations(self, mock_context):
        """æµ‹è¯•å¤§é‡æ“ä½œçš„æ€§èƒ½"""

        user_id = ChatToolsTestConfig.TEST_USER_ID
        task_service = Mock()
        mock_context.return_value.__enter__.return_value = {
            'task_service': task_service,
            'points_service': Mock()
        }

        logger.info("ğŸ”„ é«˜æ€§èƒ½æ“ä½œæµ‹è¯•")

        # åˆ›å»ºå¤§é‡ä»»åŠ¡
        start_time = time.time()
        created_tasks = []

        for i in range(50):
            task = {
                'id': str(uuid4()),
                'title': f'æ€§èƒ½æµ‹è¯•ä»»åŠ¡{i+1}',
                'description': f'ç¬¬{i+1}ä¸ªæ€§èƒ½æµ‹è¯•ä»»åŠ¡',
                'status': 'pending',
                'user_id': user_id,
                'created_at': datetime.now(timezone.utc).isoformat()
            }
            created_tasks.append(task)

        task_service.create_task.side_effect = created_tasks

        # æ‰¹é‡åˆ›å»º
        for i, task in enumerate(created_tasks):
            create_result = create_task.invoke({
                'title': task['title'],
                'description': task['description'],
                'user_id': user_id
            })
            assert ToolResponseValidator.validate_success_response(create_result)

        create_time = time.time() - start_time
        logger.info(f"âœ… åˆ›å»º50ä¸ªä»»åŠ¡è€—æ—¶: {create_time:.2f}ç§’")

        # æ‰¹é‡æŸ¥è¯¢
        start_time = time.time()
        task_service.get_tasks.return_value = created_tasks

        query_result = query_tasks.invoke({'user_id': user_id})
        query_time = time.time() - start_time

        assert ToolResponseValidator.validate_success_response(query_result)
        logger.info(f"âœ… æŸ¥è¯¢50ä¸ªä»»åŠ¡è€—æ—¶: {query_time:.2f}ç§’")

        # æ‰¹é‡æœç´¢
        start_time = time.time()
        task_service.get_tasks.return_value = created_tasks[:25]  # è¿”å›éƒ¨åˆ†ç»“æœ

        search_result = search_tasks.invoke({
            'query': 'æ€§èƒ½æµ‹è¯•',
            'limit': 100,
            'state': None,
            'user_id': user_id
        })
        search_time = time.time() - start_time

        assert json.loads(search_result)['success'] is True
        logger.info(f"âœ… æœç´¢ä»»åŠ¡è€—æ—¶: {search_time:.2f}ç§’")

        # æ€§èƒ½æ–­è¨€
        assert create_time < 5.0, f"åˆ›å»ºæ€§èƒ½ä¸è¾¾æ ‡: {create_time}ç§’"
        assert query_time < 1.0, f"æŸ¥è¯¢æ€§èƒ½ä¸è¾¾æ ‡: {query_time}ç§’"
        assert search_time < 1.0, f"æœç´¢æ€§èƒ½ä¸è¾¾æ ‡: {search_time}ç§’"

        logger.info("ğŸ‰ é«˜æ€§èƒ½æ“ä½œæµ‹è¯•é€šè¿‡ï¼")


class TestRealWorldScenarios:
    """çœŸå®ä¸–ç•Œä½¿ç”¨åœºæ™¯æµ‹è¯•"""

    @patch('src.domains.chat.tools.utils.get_task_service_context')
    def test_project_management_scenario(self, mock_context):
        """æµ‹è¯•é¡¹ç›®ç®¡ç†åœºæ™¯"""

        user_id = ChatToolsTestConfig.TEST_USER_ID
        task_service = Mock()
        mock_context.return_value.__enter__.return_value = {
            'task_service': task_service,
            'points_service': Mock()
        }

        logger.info("ğŸ”„ é¡¹ç›®ç®¡ç†åœºæ™¯æµ‹è¯•")

        # åœºæ™¯ï¼šç”¨æˆ·ç®¡ç†ä¸€ä¸ªè½¯ä»¶å¼€å‘é¡¹ç›®

        # 1. åˆ›å»ºä¸»é¡¹ç›®ä»»åŠ¡
        project_task = {
            'id': str(uuid4()),
            'title': 'å¼€å‘ç”µå•†å¹³å°',
            'description': 'å¼€å‘ä¸€ä¸ªå®Œæ•´çš„B2Cç”µå•†å¹³å°',
            'status': 'pending',
            'priority': 'high',
            'user_id': user_id,
            'created_at': datetime.now(timezone.utc).isoformat()
        }

        task_service.create_task.return_value = project_task
        task_service.get_task_by_id.return_value = project_task

        create_result = create_task.invoke({
            'title': 'å¼€å‘ç”µå•†å¹³å°',
            'description': 'å¼€å‘ä¸€ä¸ªå®Œæ•´çš„B2Cç”µå•†å¹³å°',
            'priority': 'high',
            'user_id': user_id
        })
        assert ToolResponseValidator.validate_success_response(create_result)
        project_id = project_task['id']
        logger.info("âœ… åˆ›å»ºä¸»é¡¹ç›®ä»»åŠ¡")

        # 2. åˆ†è§£ä¸ºå­ä»»åŠ¡
        phases = [
            {"title": "éœ€æ±‚åˆ†æ", "description": "æ”¶é›†å’Œåˆ†æç”¨æˆ·éœ€æ±‚"},
            {"title": "ç³»ç»Ÿè®¾è®¡", "description": "è®¾è®¡ç³»ç»Ÿæ¶æ„å’Œæ•°æ®åº“"},
            {"title": "å‰ç«¯å¼€å‘", "description": "å¼€å‘ç”¨æˆ·ç•Œé¢"},
            {"title": "åç«¯å¼€å‘", "description": "å¼€å‘APIå’Œä¸šåŠ¡é€»è¾‘"},
            {"title": "æµ‹è¯•éƒ¨ç½²", "description": "ç³»ç»Ÿæµ‹è¯•å’Œéƒ¨ç½²ä¸Šçº¿"}
        ]

        phase_tasks = []
        for phase in phases:
            phase_task = {
                'id': str(uuid4()),
                'title': phase['title'],
                'description': phase['description'],
                'status': 'pending',
                'parent_id': project_id,
                'user_id': user_id,
                'created_at': datetime.now(timezone.utc).isoformat()
            }
            phase_tasks.append(phase_task)

        task_service.create_task.side_effect = phase_tasks

        batch_result = batch_create_subtasks.invoke({
            'parent_id': project_id,
            'subtasks': phases,
            'user_id': user_id
        })
        batch_data = json.loads(batch_result)
        assert batch_data['success'] is True
        assert batch_data['data']['success_count'] == 5
        logger.info("âœ… åˆ›å»º5ä¸ªé¡¹ç›®é˜¶æ®µ")

        # 3. æŸ¥è¯¢é¡¹ç›®è¿›åº¦
        all_tasks = [project_task] + phase_tasks
        task_service.get_tasks.return_value = all_tasks

        query_result = query_tasks.invoke({'user_id': user_id})
        assert ToolResponseValidator.validate_success_response(query_result)
        logger.info("âœ… æŸ¥è¯¢é¡¹ç›®æ•´ä½“è¿›åº¦")

        # 4. æœç´¢ç‰¹å®šé˜¶æ®µ
        dev_tasks = [task for task in all_tasks if 'å¼€å‘' in task['title']]
        task_service.get_tasks.return_value = dev_tasks

        search_result = search_tasks.invoke({
            'query': 'å¼€å‘',
            'limit': 10,
            'state': None,
            'user_id': user_id
        })
        search_data = json.loads(search_result)
        assert search_data['success'] is True
        assert len(search_data['tasks']) >= 2
        logger.info("âœ… æœç´¢å¼€å‘ç›¸å…³ä»»åŠ¡")

        # 5. æ›´æ–°é˜¶æ®µçŠ¶æ€
        for task in phase_tasks[:2]:  # æ ‡è®°å‰ä¸¤ä¸ªé˜¶æ®µä¸ºå®Œæˆ
            task['status'] = 'completed'
            task_service.update_task_with_tree_structure.return_value = task

            update_result = update_task.invoke({
                'task_id': task['id'],
                'status': 'completed',
                'user_id': user_id
            })
            assert ToolResponseValidator.validate_success_response(update_result)

        logger.info("âœ… æ›´æ–°é¡¹ç›®é˜¶æ®µçŠ¶æ€")

        # 6. ä½¿ç”¨è®¡ç®—å™¨è®¡ç®—è¿›åº¦
        calc_result = calculator.invoke({'expression': '2 / 5 * 100'})
        calc_data = json.loads(calc_result)
        assert ToolResponseValidator.validate_success_response(calc_result)
        logger.info(f"âœ… é¡¹ç›®è¿›åº¦è®¡ç®—: {calc_data['data']}%")

        logger.info("ğŸ‰ é¡¹ç›®ç®¡ç†åœºæ™¯æµ‹è¯•é€šè¿‡ï¼")

    def test_user_interaction_scenario(self):
        """æµ‹è¯•ç”¨æˆ·äº¤äº’åœºæ™¯"""

        logger.info("ğŸ”„ ç”¨æˆ·äº¤äº’åœºæ™¯æµ‹è¯•")

        # åœºæ™¯ï¼šç”¨æˆ·ä½¿ç”¨èŠå¤©åŠ©æ‰‹è¿›è¡Œä»»åŠ¡ç®¡ç†

        # 1. ç”¨æˆ·å…ˆè¿›è¡ŒèŠéº»å¼€é—¨éªŒè¯
        sesame_result = sesame_opener.invoke({'command': 'èŠéº»å¼€é—¨'})
        assert ToolResponseValidator.validate_success_response(sesame_result)
        logger.info("âœ… ç”¨æˆ·é€šè¿‡èŠéº»å¼€é—¨éªŒè¯")

        # 2. ç”¨æˆ·è¿›è¡Œä¸€äº›è®¡ç®—
        calculations = [
            ('8 * 5', None),  # å·¥ä½œæ—¶é—´è®¡ç®—
            ('40 * 25', None),  # å‘¨è–ªè®¡ç®—
            ('1600 / 4', None)  # æœˆè–ªè®¡ç®—
        ]

        for expr, _ in calculations:
            calc_result = calculator.invoke({'expression': expr})
            assert ToolResponseValidator.validate_success_response(calc_result)
            calc_data = json.loads(calc_result)
            logger.info(f"âœ… è®¡ç®—ç»“æœ: {calc_data['data']}")

        logger.info("ğŸ‰ ç”¨æˆ·äº¤äº’åœºæ™¯æµ‹è¯•é€šè¿‡ï¼")


class TestLangGraphIntegration:
    """LangGraphé›†æˆæµ‹è¯•"""

    @patch('src.domains.chat.tools.utils.get_task_service_context')
    def test_tool_langgraph_compatibility(self, mock_context):
        """æµ‹è¯•å·¥å…·ä¸LangGraphçš„å…¼å®¹æ€§"""

        user_id = ChatToolsTestConfig.TEST_USER_ID
        task_service = Mock()
        mock_context.return_value.__enter__.return_value = {
            'task_service': task_service,
            'points_service': Mock()
        }

        logger.info("ğŸ”„ LangGraphå…¼å®¹æ€§æµ‹è¯•")

        # æµ‹è¯•æ‰€æœ‰å·¥å…·çš„@toolè£…é¥°å™¨å…¼å®¹æ€§
        tools_to_test = [
            (sesame_opener, {'command': 'èŠéº»å¼€é—¨'}),
            (calculator, {'expression': '10 + 20'}),
            (query_tasks, {'user_id': user_id}),
            (get_task_detail, {'task_id': str(uuid4()), 'user_id': user_id}),
            (search_tasks, {'query': 'æµ‹è¯•', 'limit': 10, 'state': None}),
            (batch_create_subtasks, {
                'parent_id': str(uuid4()),
                'subtasks': [{'title': 'æµ‹è¯•å­ä»»åŠ¡'}],
                'user_id': user_id
            })
        ]

        for tool, args in tools_to_test:
            try:
                # è®¾ç½®mockè¿”å›å€¼
                if hasattr(tool, 'name') and 'task' in tool.name:
                    if 'create' in tool.name:
                        task_service.create_task.return_value = {
                            'id': str(uuid4()),
                            'title': 'æµ‹è¯•ä»»åŠ¡',
                            'user_id': user_id,
                            'created_at': datetime.now(timezone.utc).isoformat()
                        }
                    elif 'query' in tool.name:
                        task_service.get_tasks.return_value = []
                    elif 'detail' in tool.name:
                        task_service.get_task.return_value = None
                    elif 'batch' in tool.name:
                        task_service.get_task_by_id.return_value = {
                            'id': str(uuid4()),
                            'user_id': user_id
                        }
                        task_service.create_task.return_value = {
                            'id': str(uuid4()),
                            'title': 'å­ä»»åŠ¡',
                            'user_id': user_id
                        }

                result = tool.invoke(args)

                # éªŒè¯è¿”å›å€¼æ˜¯å­—ç¬¦ä¸²ï¼ˆLangGraphè¦æ±‚ï¼‰
                assert isinstance(result, str), f"{tool.name} è¿”å›å€¼ä¸æ˜¯å­—ç¬¦ä¸²"

                # å°è¯•è§£æJSONï¼ˆå¤§éƒ¨åˆ†å·¥å…·è¿”å›JSONï¼‰
                try:
                    parsed = json.loads(result)
                    assert isinstance(parsed, dict), f"{tool.name} è¿”å›çš„JSONä¸æ˜¯å­—å…¸"
                except json.JSONDecodeError:
                    # æŸäº›å·¥å…·å¯èƒ½è¿”å›éJSONå­—ç¬¦ä¸²ï¼Œè¿™ä¹Ÿæ˜¯å¯ä»¥æ¥å—çš„
                    pass

                logger.info(f"âœ… {tool.name} LangGraphå…¼å®¹æ€§æµ‹è¯•é€šè¿‡")

            except Exception as e:
                logger.error(f"âŒ {tool.name} LangGraphå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
                raise

        logger.info("ğŸ‰ æ‰€æœ‰å·¥å…·LangGraphå…¼å®¹æ€§æµ‹è¯•é€šè¿‡ï¼")


if __name__ == "__main__":
    """è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•"""
    import sys

    test_classes = [
        TestCompleteWorkflow,
        TestToolChaining,
        TestErrorHandlingAndRecovery,
        TestPerformanceIntegration,
        TestRealWorldScenarios,
        TestLangGraphIntegration
    ]

    passed_tests = 0
    total_tests = len(test_classes)

    for test_class in test_classes:
        try:
            print(f"\nğŸ”„ è¿è¡Œ {test_class.__name__} æµ‹è¯•...")
            test_instance = test_class()

            # è¿è¡Œè¯¥ç±»ä¸­çš„æ‰€æœ‰æµ‹è¯•æ–¹æ³•
            methods = [method for method in dir(test_instance) if method.startswith('test_')]
            for method_name in methods:
                method = getattr(test_instance, method_name)
                method()

            print(f"âœ… {test_class.__name__} æµ‹è¯•é€šè¿‡")
            passed_tests += 1

        except Exception as e:
            print(f"âŒ {test_class.__name__} æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    print(f"\nğŸ“Š é›†æˆæµ‹è¯•ç»“æœ: {passed_tests}/{total_tests} é€šè¿‡")

    if passed_tests == total_tests:
        print("ğŸ‰ æ‰€æœ‰é›†æˆæµ‹è¯•é€šè¿‡ï¼")
        sys.exit(0)
    else:
        print("âŒ éƒ¨åˆ†é›†æˆæµ‹è¯•å¤±è´¥ï¼")
        sys.exit(1)