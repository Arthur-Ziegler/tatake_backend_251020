# 服务层日志系统详解

## 概述

本文档详细介绍服务层的统一日志系统，包括配置方法、使用指南、性能监控和最佳实践。

## 🏗️ 日志系统架构

### 核心组件

```
ServiceLogger (服务日志器)
├── ServiceLoggerConfig (配置管理)
├── StructuredFormatter (结构化格式化器)
├── SimpleFormatter (简单格式化器)
└── 装饰器 (Decorators)
    ├── @operation_logger (操作日志装饰器)
    └── @performance_logger (性能监控装饰器)
```

### 日志流程

```
Service Method → ServiceLogger → Formatter → Output (Console/File)
                                    ↓
                            Structured JSON Format
```

## 🔧 配置系统

### 环境变量配置

| 变量名 | 默认值 | 说明 | 可选值 |
|--------|--------|------|--------|
| `SERVICE_LOG_LEVEL` | INFO | 日志级别 | DEBUG/INFO/WARNING/ERROR/CRITICAL |
| `SERVICE_LOG_FORMAT` | structured | 日志格式 | structured/simple |
| `SERVICE_LOG_CONSOLE` | true | 控制台输出 | true/false |
| `SERVICE_LOG_FILE` | true | 文件输出 | true/false |
| `SERVICE_LOG_FILE_PATH` | logs/services.log | 日志文件路径 | 任意有效路径 |
| `SERVICE_LOG_MAX_SIZE` | 10 | 日志文件最大大小(MB) | 1-100 |
| `SERVICE_LOG_BACKUP_COUNT` | 5 | 日志备份数量 | 1-20 |
| `SERVICE_LOG_PERFORMANCE` | false | 性能监控开关 | true/false |

### 配置示例

#### 开发环境配置

```bash
# .env.dev
SERVICE_LOG_LEVEL=DEBUG
SERVICE_LOG_FORMAT=simple
SERVICE_LOG_CONSOLE=true
SERVICE_LOG_FILE=false
SERVICE_LOG_PERFORMANCE=true
```

#### 生产环境配置

```bash
# .env.prod
SERVICE_LOG_LEVEL=INFO
SERVICE_LOG_FORMAT=structured
SERVICE_LOG_CONSOLE=false
SERVICE_LOG_FILE=true
SERVICE_LOG_FILE_PATH=/var/log/tatake/services.log
SERVICE_LOG_MAX_SIZE=50
SERVICE_LOG_BACKUP_COUNT=10
SERVICE_LOG_PERFORMANCE=true
```

#### 测试环境配置

```bash
# .env.test
SERVICE_LOG_LEVEL=ERROR
SERVICE_LOG_FORMAT=simple
SERVICE_LOG_CONSOLE=false
SERVICE_LOG_FILE=false
SERVICE_LOG_PERFORMANCE=false
```

## 📝 日志格式

### 结构化JSON格式 (Structured)

```json
{
  "timestamp": "2025-10-20T10:30:45.123456Z",
  "level": "INFO",
  "logger": "services.TaskService",
  "message": "任务创建成功",
  "module": "task_service",
  "function": "create_task",
  "line": 245,
  "service": "TaskService",
  "operation": "create_task",
  "user_id": "user_123",
  "session_id": "sess_456",
  "request_id": "req_789",
  "duration_ms": 125.5,
  "extra_data": {
    "task_id": "task_abc",
    "priority": "high"
  }
}
```

### 简单格式 (Simple)

```
2025-10-20 10:30:45 | INFO     | services.TaskService | create_task:245 | 任务创建成功
```

### 字段说明

| 字段 | 类型 | 说明 |
|------|------|------|
| `timestamp` | string | ISO 8601格式的时间戳 |
| `level` | string | 日志级别 (DEBUG/INFO/WARNING/ERROR/CRITICAL) |
| `logger` | string | 日志器名称，格式为 `services.{ServiceName}` |
| `message` | string | 日志消息 |
| `module` | string | Python模块名 |
| `function` | string | 函数名 |
| `line` | number | 代码行号 |
| `service` | string | 服务类名 |
| `operation` | string | 操作名称（装饰器自动添加） |
| `user_id` | string | 用户ID（可选） |
| `session_id` | string | 会话ID（可选） |
| `request_id` | string | 请求ID（可选） |
| `duration_ms` | number | 操作耗时（毫秒，性能日志） |
| `extra_data` | object | 额外的上下文数据 |

## 🎯 使用方法

### 1. 基本日志记录

```python
class TaskService(BaseService):
    def create_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        # 基本日志
        self._log_info("开始创建任务", extra_data={"title": task_data.get("title")})

        try:
            # 业务逻辑
            task = self._create_task_in_database(task_data)

            # 成功日志
            self._log_info("任务创建成功", extra_data={"task_id": task.id})
            return task

        except Exception as e:
            # 错误日志
            self._log_error("任务创建失败", error=e, extra_data={"task_data": task_data})
            raise
```

### 2. 不同级别的日志

```python
def demonstrate_log_levels(self):
    # DEBUG级别：详细的调试信息
    self._log_debug("调试信息", variable_value=42, data_structure={"key": "value"})

    # INFO级别：一般信息
    self._log_info("操作完成", operation="user_login", user_id="123")

    # WARNING级别：警告信息
    self._log_warning("性能警告", operation="slow_query", duration_ms=5000)

    # ERROR级别：错误信息
    self._log_error("操作失败", error=exception, operation="database_update")

    # CRITICAL级别：严重错误
    self._log_critical("系统故障", component="database", error_code="DB_CONN_FAILED")
```

### 3. 操作日志装饰器

```python
from src.services.logging_config import operation_logger

class TaskService(BaseService):
    @operation_logger("创建任务", log_args=True, log_result=True)
    def create_task(self, user_id: str, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        创建任务
        装饰器会自动记录：
        - 操作开始
        - 操作参数 (log_args=True)
        - 操作结果 (log_result=True)
        - 操作成功/失败
        - 执行时间
        """
        # 验证参数
        self.validate_required_fields(task_data, ["title", "description"])

        # 创建任务
        task = self.get_task_repository().create({
            "user_id": user_id,
            **task_data,
            "created_at": datetime.now()
        })

        return self._task_to_dict(task)

    @operation_logger("删除任务", log_args=False, log_result=False)
    def delete_task(self, task_id: str, user_id: str) -> None:
        """
        删除任务
        不记录参数和结果，但记录操作状态
        """
        # 检查权限
        task = self._check_task_ownership(task_id, user_id)

        # 删除任务
        self.get_task_repository().delete(task_id)
```

### 4. 性能监控装饰器

```python
from src.services.logging_config import performance_logger

class StatisticsService(BaseService):
    @performance_logger("生成月度报告")
    def generate_monthly_report(self, user_id: str, month: str) -> Dict[str, Any]:
        """
        生成月度报告
        装饰器会自动记录执行时间
        """
        # 复杂的数据处理逻辑
        tasks = self.get_task_repository().find_by_user_and_month(user_id, month)
        focus_sessions = self.get_focus_repository().find_by_user_and_month(user_id, month)

        report = self._calculate_monthly_statistics(tasks, focus_sessions)
        return report

    @performance_logger("批量数据处理")
    def batch_process_data(self, data_list: List[Dict]) -> List[Dict]:
        """
        批量处理数据
        适合监控耗时较长的批量操作
        """
        results = []
        for data in data_list:
            processed = self._process_single_item(data)
            results.append(processed)

        return results
```

### 5. 上下文日志

```python
class UserService(BaseService):
    def update_user_profile(self, user_id: str, profile_data: Dict) -> Dict[str, Any]:
        # 开始操作，记录上下文
        self._log_operation_start("update_user_profile",
                                 user_id=user_id,
                                 update_fields=list(profile_data.keys()))

        try:
            # 验证用户存在
            user = self._check_resource_exists(
                self.get_user_repository(),
                user_id,
                "用户"
            )

            # 更新用户信息
            updated_user = self.get_user_repository().update(user_id, profile_data)

            # 记录成功，包含上下文信息
            self._log_operation_success("update_user_profile",
                                        user_id=user_id,
                                        updated_fields=list(profile_data.keys()),
                                        previous_version=user.version)

            return self._user_to_dict(updated_user)

        except Exception as e:
            # 记录失败，包含上下文信息
            self._log_operation_error("update_user_profile", e,
                                     user_id=user_id,
                                     update_fields=list(profile_data.keys()))
            raise
```

## 🔍 高级功能

### 1. 自定义日志上下文

```python
class CustomService(BaseService):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)

        # 设置自定义日志上下文
        self._log_context = {
            "service_version": "2.1.0",
            "environment": os.getenv("ENVIRONMENT", "development"),
            "instance_id": os.getenv("INSTANCE_ID", "local")
        }

    def _log_with_context(self, level: str, message: str, **kwargs):
        """带自定义上下文的日志记录"""
        all_kwargs = {**self._log_context, **kwargs}

        if level == "DEBUG":
            self._log_debug(message, **all_kwargs)
        elif level == "INFO":
            self._log_info(message, **all_kwargs)
        elif level == "WARNING":
            self._log_warning(message, **all_kwargs)
        elif level == "ERROR":
            self._log_error(message, **all_kwargs)
        elif level == "CRITICAL":
            self._log_critical(message, **all_kwargs)

    def process_data(self, data: Dict):
        self._log_with_context("INFO", "开始处理数据",
                              data_type=data.get("type"),
                              data_size=len(str(data)))
```

### 2. 条件日志记录

```python
class ConditionalLoggingService(BaseService):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self._enable_detailed_logging = os.getenv("DETAILED_LOGGING", "false").lower() == "true"

    def complex_operation(self, data: Dict):
        self._log_info("开始复杂操作")

        # 详细日志（仅在生产环境或调试时启用）
        if self._enable_detailed_logging:
            self._log_debug("详细操作步骤",
                           step=1,
                           data_preview=str(data)[:100])

        try:
            result = self._perform_operation(data)

            if self._enable_detailed_logging:
                self._log_debug("操作结果详情",
                               result_size=len(str(result)),
                               processing_time_ms=... )

            self._log_info("复杂操作完成")
            return result

        except Exception as e:
            self._log_error("复杂操作失败", error=e)
            raise
```

### 3. 日志聚合和分析

```python
class LogAggregator:
    def __init__(self):
        self.operation_counts = {}
        self.error_counts = {}
        self.performance_data = {}

    def aggregate_log_entry(self, log_entry: Dict):
        """聚合日志条目"""
        level = log_entry.get("level")
        operation = log_entry.get("operation")

        # 统计操作次数
        if operation:
            self.operation_counts[operation] = self.operation_counts.get(operation, 0) + 1

        # 统计错误次数
        if level == "ERROR":
            error_type = log_entry.get("extra_data", {}).get("error_type", "Unknown")
            self.error_counts[error_type] = self.error_counts.get(error_type, 0) + 1

        # 聚合性能数据
        if "duration_ms" in log_entry:
            if operation not in self.performance_data:
                self.performance_data[operation] = []
            self.performance_data[operation].append(log_entry["duration_ms"])

    def get_performance_summary(self, operation: str) -> Dict:
        """获取性能摘要"""
        if operation not in self.performance_data:
            return {}

        durations = self.performance_data[operation]
        return {
            "operation": operation,
            "count": len(durations),
            "avg_ms": sum(durations) / len(durations),
            "min_ms": min(durations),
            "max_ms": max(durations),
            "p95_ms": sorted(durations)[int(len(durations) * 0.95)]
        }
```

## 🛠️ 日志管理

### 1. 日志轮转配置

```python
# logging_config.py 中的配置
class ServiceLoggerConfig:
    def __init__(self):
        # 从环境变量读取配置
        self.max_log_size = int(os.getenv("SERVICE_LOG_MAX_SIZE", "10")) * 1024 * 1024
        self.backup_count = int(os.getenv("SERVICE_LOG_BACKUP_COUNT", "5"))
        self.log_file_path = os.getenv("SERVICE_LOG_FILE_PATH", "logs/services.log")

        # 创建日志目录
        if self.enable_file:
            log_dir = Path(self.log_file_path).parent
            log_dir.mkdir(parents=True, exist_ok=True)
```

### 2. 日志文件管理

```bash
# 查看日志文件
ls -la logs/

# 查看日志文件大小
du -h logs/services.log*

# 手动轮转日志（如果需要）
logrotate -f /etc/logrotate.d/tatake-services

# 清理旧日志
find logs/ -name "*.log.*" -mtime +30 -delete
```

### 3. 日志监控脚本

```python
#!/usr/bin/env python3
"""
日志监控脚本
监控错误日志并发送告警
"""

import re
import json
import time
import smtplib
from datetime import datetime
from email.mime.text import MimeText

class LogMonitor:
    def __init__(self, log_file: str):
        self.log_file = log_file
        self.error_patterns = [
            r'level":"ERROR"',
            r'level":"CRITICAL"',
            r'exception":'
        ]

    def monitor_errors(self, check_interval: int = 60):
        """监控错误日志"""
        error_count = 0
        last_position = 0

        while True:
            try:
                with open(self.log_file, 'r') as f:
                    f.seek(last_position)
                    new_lines = f.readlines()
                    last_position = f.tell()

                    for line in new_lines:
                        if any(pattern in line for pattern in self.error_patterns):
                            error_count += 1
                            log_entry = json.loads(line)
                            self.handle_error(log_entry)

                            # 如果错误过多，发送告警
                            if error_count >= 10:
                                self.send_alert("错误日志过多告警", f"在过去{check_interval}秒内发现{error_count}个错误")
                                error_count = 0

                time.sleep(check_interval)

            except Exception as e:
                print(f"日志监控异常: {e}")
                time.sleep(check_interval)

    def handle_error(self, log_entry: Dict):
        """处理单个错误日志"""
        timestamp = log_entry.get("timestamp")
        level = log_entry.get("level")
        service = log_entry.get("service")
        message = log_entry.get("message")

        print(f"[{timestamp}] {level} - {service}: {message}")

        # 可以添加更多的错误处理逻辑
        # 例如：写入错误数据库、发送到监控系统等

    def send_alert(self, subject: str, message: str):
        """发送告警邮件"""
        # 实现邮件发送逻辑
        pass

if __name__ == "__main__":
    monitor = LogMonitor("logs/services.log")
    monitor.monitor_errors()
```

## 📊 日志分析

### 1. 错误日志分析

```bash
# 统计错误类型
grep "level\":\"ERROR" logs/services.log | jq -r '.message' | sort | uniq -c | sort -nr

# 查看最近的错误
tail -100 logs/services.log | grep "level\":\"ERROR" | jq

# 分析错误趋势
grep "level\":\"ERROR" logs/services.log | jq -r '.timestamp' | cut -c1-13 | sort | uniq -c
```

### 2. 性能日志分析

```bash
# 查看最慢的操作
grep "duration_ms" logs/services.log | jq -c 'select(.duration_ms > 1000)' | sort -r

# 统计操作性能
grep "operation" logs/services.log | jq -r 'select(.duration_ms) | "\(.operation):\(.duration_ms)"' | \
awk -F: '{sum[$1] += $2; count[$1] += 1} END {for (op in sum) print op, sum[op]/count[op], count[op]}' | \
sort -k2 -nr
```

### 3. 用户行为分析

```bash
# 分析用户操作频率
grep "user_id" logs/services.log | jq -r '.user_id' | sort | uniq -c | sort -nr | head -10

# 分析操作类型分布
grep "operation" logs/services.log | jq -r '.operation' | sort | uniq -c | sort -nr
```

## 🔧 故障排除

### 1. 常见日志问题

| 问题 | 原因 | 解决方案 |
|------|------|----------|
| 日志文件过大 | 轮转配置不当 | 调整 `SERVICE_LOG_MAX_SIZE` 和 `SERVICE_LOG_BACKUP_COUNT` |
| 日志不显示 | 日志级别设置过高 | 降低 `SERVICE_LOG_LEVEL` 到 DEBUG 或 INFO |
| 性能影响 | 详细日志过多 | 关闭 `SERVICE_LOG_PERFORMANCE` 或提高日志级别 |
| 磁盘空间不足 | 日志文件过多 | 增加日志清理脚本，调整备份配置 |

### 2. 调试技巧

```python
# 临时启用详细日志
import os
os.environ['SERVICE_LOG_LEVEL'] = 'DEBUG'
os.environ['SERVICE_LOG_PERFORMANCE'] = 'true'

# 重新创建服务实例
service = TaskService()

# 现在会看到详细的调试日志
```

### 3. 日志验证

```python
def test_logging_system():
    """测试日志系统是否正常工作"""
    from src.services.logging_config import get_logger

    logger = get_logger("TestService")

    # 测试各级别日志
    logger.debug("测试DEBUG日志")
    logger.info("测试INFO日志")
    logger.warning("测试WARNING日志")
    logger.error("测试ERROR日志")

    # 测试操作日志
    logger.log_operation_start("测试操作")
    logger.log_operation_success("测试操作", duration_ms=100)

    print("日志系统测试完成，请检查日志输出")
```

## 📈 性能考虑

### 1. 日志性能优化

```python
# 使用延迟字符串格式化
def optimized_logging(self, large_data: Dict):
    # ❌ 不推荐：立即格式化大字符串
    # self._log_debug(f"大数据: {json.dumps(large_data)}")

    # ✅ 推荐：只在需要时格式化
    if self._logger.isEnabledFor(logging.DEBUG):
        self._log_debug("大数据", data_preview=str(large_data)[:100])

# 避免在热路径中记录详细日志
def hot_path_operation(self):
    # ❌ 不推荐：在循环中记录日志
    # for item in large_list:
    #     self._log_debug("处理项目", item=item)

    # ✅ 推荐：记录汇总信息
    self._log_info("开始批量处理", total_items=len(large_list))

    for item in large_list:
        self._process_item(item)

    self._log_info("批量处理完成")
```

### 2. 异步日志记录

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class AsyncLogger:
    def __init__(self, logger):
        self.logger = logger
        self.executor = ThreadPoolExecutor(max_workers=2)

    async def log_async(self, level: str, message: str, **kwargs):
        """异步记录日志"""
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(
            self.executor,
            getattr(self.logger, level.lower()),
            message,
            **kwargs
        )

    def close(self):
        """关闭日志器"""
        self.executor.shutdown(wait=True)
```

## 🎯 最佳实践总结

### 1. 日志级别使用指南

- **DEBUG**: 详细的调试信息，仅在开发时使用
- **INFO**: 一般信息，记录重要的业务操作
- **WARNING**: 警告信息，潜在的问题
- **ERROR**: 错误信息，操作失败但系统可继续运行
- **CRITICAL**: 严重错误，可能影响系统正常运行

### 2. 日志内容原则

- **结构化**: 使用JSON格式，便于解析和分析
- **上下文**: 包含足够的上下文信息（用户ID、操作ID等）
- **简洁**: 避免冗余信息，重点突出
- **一致**: 使用统一的字段命名和格式

### 3. 性能考虑

- **适度记录**: 避免过度记录影响性能
- **异步处理**: 考虑异步日志记录
- **条件日志**: 根据环境或配置选择性记录
- **定期清理**: 及时清理和归档历史日志

---

**最后更新**: 2025-10-20
**版本**: 1.0.0
**维护者**: 开发团队