#!/usr/bin/env python3
"""
è°ƒè¯•èŠå¤©å·¥å…·è°ƒç”¨æµç¨‹
"""

import os
import sys
import uuid
import logging
from dotenv import load_dotenv

# è®¾ç½®è·¯å¾„
sys.path.append('src')

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

from langchain_core.messages import HumanMessage
from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.store.memory import InMemoryStore

from domains.chat.database import create_chat_checkpointer, create_memory_store
from domains.chat.graph import create_chat_graph
from domains.chat.models import ChatState

def test_graph_workflow():
    """æµ‹è¯•å®Œæ•´çš„å›¾å·¥ä½œæµç¨‹"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•èŠå¤©å›¾å·¥ä½œæµç¨‹...")

    # åˆ›å»ºæ£€æŸ¥ç‚¹å’Œå­˜å‚¨ï¼ˆä½¿ç”¨ä¸å®é™…ç›¸åŒçš„é…ç½®ï¼‰
    checkpointer = create_chat_checkpointer()
    store = create_memory_store()

    # åˆ›å»ºå›¾
    graph = create_chat_graph(checkpointer, store)

    # æ¨¡æ‹Ÿç”¨æˆ·å’Œä¼šè¯
    user_id = "test-user-123"
    session_id = str(uuid.uuid4())

    # åˆ›å»ºé…ç½®
    config = {
        "configurable": {
            "thread_id": session_id,
            "user_id": user_id
        }
    }

    # åˆ›å»ºåˆå§‹çŠ¶æ€
    initial_state = {
        "user_id": user_id,
        "session_id": session_id,
        "session_title": "æµ‹è¯•ä¼šè¯",
        "messages": [HumanMessage(content="å¿«ä½¿ç”¨èŠéº»å¼€é—¨å·¥å…·")]
    }

    print(f"ğŸ‘¤ ç”¨æˆ·ID: {user_id}")
    print(f"ğŸ†” ä¼šè¯ID: {session_id}")
    print(f"ğŸ’¬ æ¶ˆæ¯: å¿«ä½¿ç”¨èŠéº»å¼€é—¨å·¥å…·")

    try:
        # è¿è¡Œå›¾
        result = graph.invoke(initial_state, config)

        print("\nâœ… å›¾æ‰§è¡ŒæˆåŠŸ!")
        print(f"ğŸ“ æœ€ç»ˆçŠ¶æ€æ¶ˆæ¯æ•°é‡: {len(result.get('messages', []))}")

        # åˆ†ææ¶ˆæ¯
        messages = result.get('messages', [])
        for i, msg in enumerate(messages):
            msg_type = type(msg).__name__
            content = msg.content if hasattr(msg, 'content') else str(msg)
            tool_calls = getattr(msg, 'tool_calls', None)

            print(f"\nğŸ“¨ æ¶ˆæ¯ {i+1}:")
            print(f"   ç±»å‹: {msg_type}")
            print(f"   å†…å®¹: {content[:100]}..." if len(content) > 100 else f"   å†…å®¹: {content}")
            if tool_calls:
                print(f"   å·¥å…·è°ƒç”¨: {tool_calls}")

        return True

    except Exception as e:
        print(f"\nâŒ å›¾æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_simple_tool_call():
    """æµ‹è¯•ç®€å•çš„å·¥å…·è°ƒç”¨"""
    print("\nğŸ”§ æµ‹è¯•ç®€å•å·¥å…·è°ƒç”¨...")

    from domains.chat.tools.password_opener import sesame_opener
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import HumanMessage

    model = ChatOpenAI(
        model='gpt-3.5-turbo',
        api_key=os.getenv('OPENAI_API_KEY'),
        base_url=os.getenv('OPENAI_BASE_URL'),
        temperature=0.7
    )

    model_with_tools = model.bind_tools([sesame_opener])

    messages = [HumanMessage(content="è¯·ä½¿ç”¨èŠéº»å¼€é—¨å·¥å…·")]
    response = model_with_tools.invoke(messages)

    print(f"ğŸ¤– AIå“åº”: {response.content}")
    if hasattr(response, 'tool_calls') and response.tool_calls:
        print(f"âœ… å·¥å…·è°ƒç”¨: {response.tool_calls}")

        # æ‰§è¡Œå·¥å…·
        for tool_call in response.tool_calls:
            result = sesame_opener.invoke(tool_call['args'])
            print(f"ğŸ”§ å·¥å…·ç»“æœ: {result}")
    else:
        print("âŒ æ— å·¥å…·è°ƒç”¨")

if __name__ == "__main__":
    print("=" * 60)
    print("èŠå¤©å·¥å…·è°ƒç”¨è°ƒè¯•")
    print("=" * 60)

    # æµ‹è¯•ç®€å•å·¥å…·è°ƒç”¨
    test_simple_tool_call()

    # æµ‹è¯•å®Œæ•´å›¾å·¥ä½œæµ
    success = test_graph_workflow()

    print("\n" + "=" * 60)
    if success:
        print("âœ… æµ‹è¯•å®Œæˆ")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥")
    print("=" * 60)