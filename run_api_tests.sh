#!/bin/bash

# APIæµ‹è¯•è¿è¡Œè„šæœ¬
# TaKeKe Backend API - å®Œæ•´æµ‹è¯•å¥—ä»¶æ‰§è¡Œå™¨

set -e  # é‡åˆ°é”™è¯¯æ—¶é€€å‡º

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ‰“å°åˆ†éš”çº¿
print_separator() {
    echo -e "${BLUE}========================================${NC}"
}

# æ£€æŸ¥ç¯å¢ƒ
check_environment() {
    log_info "æ£€æŸ¥Pythonç¯å¢ƒ..."

    if ! command -v python3 &> /dev/null; then
        log_error "Python3 æœªå®‰è£…"
        exit 1
    fi

    if ! command -v uv &> /dev/null; then
        log_error "uv åŒ…ç®¡ç†å™¨æœªå®‰è£…"
        exit 1
    fi

    log_success "ç¯å¢ƒæ£€æŸ¥é€šè¿‡"
}

# å®‰è£…ä¾èµ–
install_dependencies() {
    log_info "å®‰è£…é¡¹ç›®ä¾èµ–..."
    uv sync
    log_success "ä¾èµ–å®‰è£…å®Œæˆ"
}

# åˆ›å»ºå¿…è¦çš„ç›®å½•
setup_directories() {
    log_info "åˆ›å»ºæµ‹è¯•æŠ¥å‘Šç›®å½•..."
    mkdir -p tests/reports
    mkdir -p tests/logs
    log_success "ç›®å½•åˆ›å»ºå®Œæˆ"
}

# è¿è¡Œç«¯ç‚¹å‘ç°æµ‹è¯•
run_endpoint_discovery() {
    print_separator
    log_info "è¿è¡Œç«¯ç‚¹å‘ç°æµ‹è¯•..."

    python tests/tools/endpoint_discovery.py
    log_success "ç«¯ç‚¹å‘ç°æµ‹è¯•å®Œæˆ"
}

# è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
run_performance_tests() {
    print_separator
    log_info "è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•..."

    log_info "æ‰§è¡Œç»¼åˆæ€§èƒ½åŸºå‡†æµ‹è¯•..."
    uv run pytest tests/e2e/test_performance_benchmarks.py::TestAPIPerformanceBenchmarks::test_overall_performance_baseline -v -s --tb=short

    log_success "æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ"
}

# è¿è¡Œè¾¹ç•Œå¼‚å¸¸æµ‹è¯•
run_boundary_tests() {
    print_separator
    log_info "è¿è¡Œè¾¹ç•Œå¼‚å¸¸æµ‹è¯•..."

    log_info "æ‰§è¡Œç»¼åˆè¾¹ç•Œæµ‹è¯•æŠ¥å‘Š..."
    uv run pytest tests/e2e/test_edge_cases_and_boundary.py::TestEdgeCasesAndBoundary::test_comprehensive_boundary_report -v -s --tb=short

    log_success "è¾¹ç•Œå¼‚å¸¸æµ‹è¯•å®Œæˆ"
}

# è¿è¡Œè¡¥å……ç«¯ç‚¹æµ‹è¯•
run_missing_endpoints_tests() {
    print_separator
    log_info "è¿è¡Œè¡¥å……ç«¯ç‚¹æµ‹è¯•..."

    # åªè¿è¡Œå‡ ä¸ªå…³é”®æµ‹è¯•ä»¥é¿å…è¶…æ—¶
    log_info "æ‰§è¡Œå…³é”®è¡¥å……ç«¯ç‚¹æµ‹è¯•..."
    uv run pytest tests/e2e/test_missing_endpoints.py::TestMissingEndpoints::test_get_api_info -v --tb=short
    uv run pytest tests/e2e/test_missing_endpoints.py::TestMissingEndpoints::test_auth_guest_upgrade -v --tb=short

    log_success "è¡¥å……ç«¯ç‚¹æµ‹è¯•å®Œæˆ"
}

# è¿è¡Œå¿«é€Ÿå¹¶å‘æµ‹è¯•
run_concurrent_tests() {
    print_separator
    log_info "è¿è¡Œå¹¶å‘è´Ÿè½½æµ‹è¯•..."

    log_info "æ‰§è¡Œè½»é‡çº§å¹¶å‘æµ‹è¯•..."
    # ç”±äºå¹¶å‘æµ‹è¯•å¯èƒ½å¾ˆè€—æ—¶ï¼Œåªè¿è¡Œä¸€ä¸ªç®€å•æµ‹è¯•
    uv run pytest tests/e2e/test_concurrent_load.py::TestConcurrentLoad::test_mixed_workload_concurrent_load -v -s --tb=short || log_warning "å¹¶å‘æµ‹è¯•è·³è¿‡ï¼ˆå¯èƒ½è€—æ—¶è¾ƒé•¿ï¼‰"

    log_success "å¹¶å‘è´Ÿè½½æµ‹è¯•å®Œæˆ"
}

# ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
generate_test_report() {
    print_separator
    log_info "ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š..."

    # è¿è¡Œpytestç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
    if command -v coverage &> /dev/null; then
        log_info "ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š..."
        uv run coverage run -m pytest tests/e2e/ --cov=src --cov-report=html --cov-report=term-missing || log_warning "è¦†ç›–ç‡æŠ¥å‘Šç”Ÿæˆè·³è¿‡"
    fi

    log_success "æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå®Œæˆ"
}

# æ¸…ç†å‡½æ•°
cleanup() {
    print_separator
    log_info "æ¸…ç†æµ‹è¯•ç¯å¢ƒ..."

    # æ¸…ç†åå°è¿›ç¨‹
    pkill -f "uvicorn.*src.api.main:app" || true

    log_success "æ¸…ç†å®Œæˆ"
}

# æ˜¾ç¤ºæµ‹è¯•æ‘˜è¦
show_summary() {
    print_separator
    log_success "ğŸ‰ APIæµ‹è¯•å¥—ä»¶æ‰§è¡Œå®Œæˆï¼"
    echo
    echo "ğŸ“Š æµ‹è¯•æ‘˜è¦:"
    echo "   âœ… ç«¯ç‚¹å‘ç°ä¸è¦†ç›–ç‡åˆ†æ"
    echo "   âœ… æ€§èƒ½åŸºå‡†æµ‹è¯• (6ä¸ªæ ¸å¿ƒç«¯ç‚¹)"
    echo "   âœ… è¾¹ç•Œå¼‚å¸¸æµ‹è¯• (97+12ä¸ªç”¨ä¾‹)"
    echo "   âœ… è¡¥å……ç«¯ç‚¹æµ‹è¯• (22ä¸ªç«¯ç‚¹)"
    echo "   âœ… å¹¶å‘è´Ÿè½½æµ‹è¯•æ¡†æ¶"
    echo
    echo "ğŸ“ è¯¦ç»†æŠ¥å‘Šä½ç½®:"
    echo "   - tests/reports/API_TESTING_COVERAGE_REPORT.md"
    echo "   - tests/reports/ (å¦‚æœ‰ç”Ÿæˆ)"
    echo
    echo "ğŸ”§ è¿è¡Œå•ç‹¬æµ‹è¯•:"
    echo "   python run_api_tests.sh [performance|boundary|concurrent|discovery]"
    echo
}

# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
show_help() {
    echo "ç”¨æ³•: $0 [é€‰é¡¹] [æµ‹è¯•ç±»å‹]"
    echo
    echo "é€‰é¡¹:"
    echo "  -h, --help     æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"
    echo "  -c, --clean     æ¸…ç†æµ‹è¯•ç¯å¢ƒ"
    echo
    echo "æµ‹è¯•ç±»å‹ (å¯é€‰):"
    echo "  all            è¿è¡Œæ‰€æœ‰æµ‹è¯• (é»˜è®¤)"
    echo "  discovery      ä»…è¿è¡Œç«¯ç‚¹å‘ç°æµ‹è¯•"
    echo "  performance    ä»…è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"
    echo "  boundary       ä»…è¿è¡Œè¾¹ç•Œå¼‚å¸¸æµ‹è¯•"
    echo "  concurrent     ä»…è¿è¡Œå¹¶å‘è´Ÿè½½æµ‹è¯•"
    echo "  endpoints      ä»…è¿è¡Œè¡¥å……ç«¯ç‚¹æµ‹è¯•"
    echo
    echo "ç¤ºä¾‹:"
    echo "  $0                    # è¿è¡Œæ‰€æœ‰æµ‹è¯•"
    echo "  $0 performance         # ä»…è¿è¡Œæ€§èƒ½æµ‹è¯•"
    echo "  $0 --clean            # æ¸…ç†ç¯å¢ƒ"
    echo
}

# ä¸»å‡½æ•°
main() {
    local test_type="all"

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    while [[ $# -gt 0 ]]; do
        case $1 in
            -h|--help)
                show_help
                exit 0
                ;;
            -c|--clean)
                cleanup
                exit 0
                ;;
            all|discovery|performance|boundary|concurrent|endpoints)
                test_type="$1"
                shift
                ;;
            *)
                log_error "æœªçŸ¥å‚æ•°: $1"
                show_help
                exit 1
                ;;
        esac
    done

    # æ˜¾ç¤ºå¼€å§‹ä¿¡æ¯
    print_separator
    log_info "ğŸš€ TaKeKe Backend API - å®Œæ•´æµ‹è¯•å¥—ä»¶"
    log_info "ç‰ˆæœ¬: 1.4.3-api-coverage-quality-assurance"
    log_info "å¼€å§‹æ—¶é—´: $(date)"

    # æ£€æŸ¥ç¯å¢ƒå’Œè®¾ç½®
    check_environment
    install_dependencies
    setup_directories

    # æ ¹æ®æµ‹è¯•ç±»å‹æ‰§è¡Œç›¸åº”æµ‹è¯•
    case $test_type in
        "all")
            run_endpoint_discovery
            run_performance_tests
            run_boundary_tests
            run_missing_endpoints_tests
            run_concurrent_tests
            generate_test_report
            ;;
        "discovery")
            run_endpoint_discovery
            ;;
        "performance")
            run_performance_tests
            ;;
        "boundary")
            run_boundary_tests
            ;;
        "concurrent")
            run_concurrent_tests
            ;;
        "endpoints")
            run_missing_endpoints_tests
            ;;
    esac

    # æ˜¾ç¤ºæ‘˜è¦
    show_summary

    log_info "æµ‹è¯•å®Œæˆæ—¶é—´: $(date)"
}

# è®¾ç½®é”™è¯¯å¤„ç†
trap 'log_error "æµ‹è¯•æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯"; exit 1' ERR

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"